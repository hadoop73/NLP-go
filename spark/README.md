



- [数据去重问题](#a1)

- [提取数据](#a2)

- [数据排序](#a3)

- [算子介绍](#a4)

- [平均成绩](#a5)

- [最大最小值](#a6)

<h2 id='a1'>去重数据</h2>

[Python 实现](t2.py)

[Hadoop经典案例Spark实现（二）——数据去重问题](http://blog.csdn.net/kwu_ganymede/article/details/50474763)



<h2 id='a2'>提取数据</h2>

[Python 实现](t1.py)

[Hadoop经典案例Spark实现（一）——通过采集的气象数据分析每年的最高温度](http://blog.csdn.net/kwu_ganymede/article/details/50464343)




<h2 id='a3'>数据排序</h2>

[Python 实现](t3.py)

[Hadoop经典案例Spark实现（三）——数据排序](http://blog.csdn.net/kwu_ganymede/article/details/50475788)


<h2 id='a5'>平均成绩</h2>

[Python 实现](t4.py)

![enter description here][1]

<h2 id='a6'>最大最小值</h2>

[Python 实现](t5.py)


<h2 id='a7'>TopN排序</h2>

[Python 实现](t6.py)




<h2 id='a4'>算子介绍</h2>

- **combineByKey()**

[spark combinebykey？](https://www.zhihu.com/question/33798481)

![enter description here][2]

![enter description here][3]

- **aggregate()**


  [1]: ./images/1491159596104.jpg "1491159596104.jpg"
  [2]: ./images/1491158523018.jpg "1491158523018.jpg"
  [3]: ./images/1491158510255.jpg "1491158510255.jpg"
